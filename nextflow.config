/*
 * -------------------------------------------------
 *  nf-core/rnaseq Nextflow config file
 * -------------------------------------------------
 * Default config options for all environments.
 */

// Global default params, used in configs
params {

  // Pipeline Options
  // Workflow flags
  input = "data/*{1,2}.fastq.gz"
  single_end = false
  input_paths = false

  // References
  genome = false
  salmon_index = false
  transcript_fasta = false
  additional_fasta = false
  splicesites = false
  save_reference = false
  gencode = false
  rsem_index = false
  star_index_options = ''

  // Strandedness
  forward_stranded = false
  reverse_stranded = false
  unstranded = false

  // UMI handling
  with_umi = false
  umitools_extract_method = "string"
  umitools_bc_pattern = false
  umitools_extract_extra = ""
  umitools_dedup_extra = ""
  save_umi_intermeds = false

  // Trimming
  skip_trimming = false
  clip_r1 = 0
  clip_r2 = 0
  three_prime_clip_r1 = 0
  three_prime_clip_r2 = 0
  trim_nextseq = 0
  pico = false
  save_trimmed = false

  // Ribosomal RNA removal
  remove_ribo_rna = false
  save_non_ribo_reads = false
  ribo_database_manifest = "$baseDir/assets/rrna-db-defaults.txt"

  // Alignment
  aligner = 'star'
  pseudo_aligner = false
  star_align_options = ''
  hisat2_align_options = ''
  stringtie_ignore_gtf = false
  seq_center = false
  save_align_intermeds = false
  skip_rsem = false
  skip_alignment = false
  save_unaligned = false
  percent_aln_skip = 5

  // Read Countinga
  fc_extra_attributes = 'gene_name'
  fc_group_features = 'gene_id'
  fc_count_type = 'exon'
  fc_group_features_type = 'gene_biotype'
  sample_level = false
  skip_biotype_qc = false

  // QC
  skip_qc = false
  skip_fastqc = false
  skip_preseq = false
  skip_dupradar = false
  skip_qualimap = false
  skip_rseqc = false
  skip_edger = false
  skip_multiqc = false

  // Defaults
  project = false
  markdup_java_options = '"-Xms4000m -Xmx7g"' //Established values for markDuplicate memory consumption, see issue PR #689 (in Sarek) for details
  hisat_build_memory = 200 // Required amount of memory in GB to build HISAT2 index with splice sites
  star_memory = false // Cluster specific param required for hebbe

  // Boilerplate options
  clusterOptions = false
  outdir = './results'
  publish_dir_mode = "copy"
  name = false
  multiqc_config = false
  email = false
  email_on_fail = false
  max_multiqc_email_size = 25.MB
  plaintext_email = false
  monochrome_logs = false
  help = false
  igenomes_base = 's3://ngi-igenomes/igenomes/'
  tracedir = "${params.outdir}/pipeline_info"
  igenomes_ignore = false
  custom_config_version = 'master'
  custom_config_base = "https://raw.githubusercontent.com/nf-core/configs/${params.custom_config_version}"
  hostnames = false
  config_profile_description = false
  config_profile_contact = false
  config_profile_url = false

  // Defaults only, expecting to be overwritten
  max_memory = 128.GB
  max_cpus = 16
  max_time = 240.h
  
  // google-lifeSciences specific
  gls_zone = 'us-east1-b'
  gls_network = 'default'
  gls_subnetwork = 'default'

  // configuration related params
  config = 'conf/google.config'
  config = 'conf/standard.config'
  echo = false
  errorStrategy = 'finish'
  maxRetries = 9
  maxForks = 200
  queueSize = 200
  executor = false
}

// Container slug. Stable releases should specify release tag!
// Developmental code should specify :dev
process.container = 'lifebitai/nf-core-rnaseq:1.4.3dev'

// Load base.config by default for all pipelines
includeConfig 'conf/base.config'
docker.enabled = true

// Load nf-core custom profiles from different Institutions
try {
  includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
  System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

profiles {
  conda { process.conda = "$baseDir/environment.yml" }
  debug { process.beforeScript = 'echo $HOSTNAME' }
  docker {
    docker.enabled = true
    // Avoid this error:
    //   WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
    // Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351
    // once this is established and works well, nextflow might implement this behavior as new default.
    docker.runOptions = '-u \$(id -u):\$(id -g)'
  }
  singularity {
    singularity.enabled = true
    singularity.autoMounts = true
  }
  minimal_salmon_quant_test { includeConfig 'conf/minimal_salmon_quant_test.config' }
  test      { includeConfig 'conf/test.config'      }
  test_full { includeConfig 'conf/test_full.config' }
  test_gz   { includeConfig 'conf/test_gz.config'   }
  test_pe   { includeConfig 'conf/test_pe.config'   }
  standard  { includeConfig params.config }
}

// Load igenomes.config if required
if (!params.igenomes_ignore) {
  includeConfig 'conf/igenomes.config'
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
env {
  PYTHONNOUSERSITE = 1
  R_PROFILE_USER = "/.Rprofile"
  R_ENVIRON_USER = "/.Renviron"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag.svg"
}

manifest {
  name = 'nf-core/rnaseq'
  author = 'Phil Ewels, Rickard HammarÃ©n'
  homePage = 'https://github.com/nf-core/rnaseq'
  description = 'Nextflow RNA-Seq analysis pipeline, part of the nf-core community.'
  mainScript = 'main.nf'
  nextflowVersion = '>=20.07.1'
  version = '1.4.3dev'
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}

executor {
    name = params.executor
    queueSize = params.queueSize
}